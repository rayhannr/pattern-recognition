{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer dan Jaccard Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diberikan 10 buah dokumen (Doc1 s.d Doc10) dalam format .txt yang berisikan abstrak dari 10 paper yang berbeda. Paper diambil dari IJCCS (Indonesian Journal of Computing and Cybernetics Systems) dalam waktu 5 tahun terakhir menggunakan bahasa Indonesia. Tujuan dari kode program ini adalah mencari Count Vectorizer dan membandingkan tingkat kemiripan 10 abstrak paper tersebut dengan metode Jaccard Similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inisialisasi Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pada Tiap Dokumen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, semua kata pada tiap-tiap dokumen akan diproses terlebih dahulu supaya lebih rapi.\n",
    "Tahap preprocessing terdiri dari :\n",
    "1. Menghilangkan spasi\n",
    "2. Mengubah semua huruf menjadi huruf kecil\n",
    "3. Menghilangkan simbol dan angka\n",
    "4. Melakukan stemming (mengubah kata ke bentuk dasarnya)\n",
    "5. Tokenisasi kalimat menjadi array berisi kata\n",
    "6. Menghilangkan kata di array tersebut yang termasuk dalam stopwords Bahasa Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "corpus = [] #array containing words in each document\n",
    "for i in range(10):\n",
    "    abstract_file = open(\"abstrak{}.txt\".format(i+1), \"r\", encoding=\"utf-8\")\n",
    "    abstract_words = []\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopwords = StopWordRemoverFactory().create_stop_word_remover()\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    \n",
    "    #extracting words in every line of the selected abstract\n",
    "    for line in abstract_file:\n",
    "        if line.strip():\n",
    "            sentence = sent_tokenize(line)\n",
    "            for word in sentence:\n",
    "                word = word.lower()\n",
    "                word = re.sub(r'[^a-zA-Z]',' ', word)\n",
    "                word = stemmer.stem(word)\n",
    "                word = word_tokenize(word)\n",
    "                word = [w for w in word if not w in factory.get_stop_words()]\n",
    "                abstract_words += word          \n",
    "    abstract_file.close()\n",
    "    \n",
    "    corpus.append(abstract_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan Semua Kata yang Unik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeding the bag of words, containing all words in all abstracts uniquely\n",
    "bag_of_words = []\n",
    "for document in corpus:\n",
    "    bag_of_words = np.concatenate((bag_of_words, document), axis=None)\n",
    "    bag_of_words  = np.unique(bag_of_words)\n",
    "    \n",
    "bag_of_words = bag_of_words.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung Count Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating Count Vectorizer\n",
    "cv = np.zeros((bag_of_words.shape[1], 10))\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(len(cv)):\n",
    "        cv[j, i] = corpus[i].count(bag_of_words[0, j])\n",
    "cv = cv.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghtiung Jaccard Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating Jaccard Similarity\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    union = 0\n",
    "    intersection = 0\n",
    "    for i in range(len(doc1)):\n",
    "        if doc1[i] > 0 and doc2[i] > 0:\n",
    "            intersection += 1\n",
    "            union += 1\n",
    "        elif doc1[i] > 0 or doc2[i] > 0:\n",
    "            union += 1\n",
    "    \n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Matrix yang Berisi Tingkat Kemiripan Antar Dokumen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating matrix showing similarity of each document\n",
    "doc_similarity = np.zeros((len(corpus), len(corpus)))\n",
    "for i in range(doc_similarity.shape[0]):\n",
    "    doc_similarity[i, i] = 1\n",
    "    for j in range(i+1, doc_similarity.shape[1]):\n",
    "        doc_similarity[i, j] = jaccard_similarity(cv[i], cv[j])\n",
    "        doc_similarity[j, i] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merepresentasikan Tingkat Kemiripan Dalam Bentuk Tabel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "      <th>Doc3</th>\n",
       "      <th>Doc4</th>\n",
       "      <th>Doc5</th>\n",
       "      <th>Doc6</th>\n",
       "      <th>Doc7</th>\n",
       "      <th>Doc8</th>\n",
       "      <th>Doc9</th>\n",
       "      <th>Doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0701754</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.147287</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.167939</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.203704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.11039</td>\n",
       "      <td>0.141791</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.0914634</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>0.125984</td>\n",
       "      <td>0.141844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.0952381</td>\n",
       "      <td>0.0980392</td>\n",
       "      <td>0.10219</td>\n",
       "      <td>0.130719</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.162791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.121495</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.0725806</td>\n",
       "      <td>0.115108</td>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.081967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.141593</td>\n",
       "      <td>0.0942029</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.132743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.152866</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.170370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.15493</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.253846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.284211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Doc1      Doc2     Doc3       Doc4       Doc5       Doc6       Doc7  \\\n",
       "Doc1     1  0.110294     0.12  0.0701754   0.145631   0.147287   0.119658   \n",
       "Doc2               1  0.11039   0.141791   0.103704  0.0914634   0.140845   \n",
       "Doc3                        1      0.136  0.0952381  0.0980392    0.10219   \n",
       "Doc4                                   1   0.121495   0.119403  0.0725806   \n",
       "Doc5                                              1   0.140625   0.141593   \n",
       "Doc6                                                         1   0.152174   \n",
       "Doc7                                                                    1   \n",
       "Doc8                                                                        \n",
       "Doc9                                                                        \n",
       "Doc10                                                                       \n",
       "\n",
       "            Doc8      Doc9     Doc10  \n",
       "Doc1    0.167939  0.191489  0.203704  \n",
       "Doc2    0.128834  0.125984  0.141844  \n",
       "Doc3    0.130719  0.118644  0.162791  \n",
       "Doc4    0.115108  0.106796  0.081967  \n",
       "Doc5   0.0942029  0.145833  0.132743  \n",
       "Doc6    0.152866  0.196581  0.170370  \n",
       "Doc7     0.15493  0.194175  0.205128  \n",
       "Doc8           1      0.25  0.253846  \n",
       "Doc9                     1  0.284211  \n",
       "Doc10                       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"Doc1\", \"Doc2\", \"Doc3\", \"Doc4\", \"Doc5\", \"Doc6\", \"Doc7\", \"Doc8\", \"Doc9\", \"Doc10\"]\n",
    "a = pd.DataFrame(doc_similarity, columns=labels, index=labels)\n",
    "#Mengubah cell yang bernilai NaN menjadi empty string ('')\n",
    "a.replace(np.nan, '', inplace=True)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
