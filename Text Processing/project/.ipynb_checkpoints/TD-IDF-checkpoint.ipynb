{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mencari TF-IDF dan Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diberikan 10 buah dokumen (Doc1 s.d Doc10) dalam format .txt yang berisikan abstrak dari 10 paper yang berbeda. Paper diambil dari IJCCS (Indonesian Journal of Computing and Cybernetics Systems) dalam waktu 5 tahun terakhir menggunakan bahasa Indonesia. Tujuan dari kode program ini adalah mencari nilai TF-IDF dan membandingkan tingkat kemiripan 10 abstrak paper tersebut dengan metode Cosine Similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inisialisasi Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pada Tiap Dokumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, semua kata pada tiap-tiap dokumen akan diproses terlebih dahulu supaya lebih rapi.\n",
    "Tahap preprocessing terdiri dari :\n",
    "1. Menghilangkan spasi\n",
    "2. Mengubah semua huruf menjadi huruf kecil\n",
    "3. Menghilangkan simbol dan angka\n",
    "4. Menghilangkan stopwords pada kata Bahasa Indonesia\n",
    "5. Melakukan stemming (mengubah kata ke bentuk dasarnya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "corpus = [] #array containing words in each document\n",
    "for i in range(10):\n",
    "    abstract_file = open(\"abstrak{}.txt\".format(i+1), \"r\", encoding=\"utf-8\")\n",
    "    abstract_words = []\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopwords = StopWordRemoverFactory().create_stop_word_remover()\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    \n",
    "    #extracting words in every line of the selected abstract\n",
    "    for line in abstract_file:\n",
    "        if line.strip():\n",
    "            sentence = sent_tokenize(line)\n",
    "            for word in sentence:\n",
    "                word = word.lower()\n",
    "                word = re.sub(r'[^a-zA-Z]',' ', word)\n",
    "                word = stemmer.stem(word)\n",
    "                word = word_tokenize(word)\n",
    "                word = [w for w in word if not w in factory.get_stop_words()]\n",
    "                abstract_words += word          \n",
    "    abstract_file.close()\n",
    "    \n",
    "    corpus.append(abstract_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan Semua Kata yang Unik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeding the bag of words, containing all words in all abstracts uniquely\n",
    "bag_of_words = []\n",
    "for document in corpus:\n",
    "    bag_of_words = np.concatenate((bag_of_words, document), axis=None)\n",
    "    bag_of_words  = np.unique(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung Term Frequency (TF) dan Dinormalisasikan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the Term Frequency    \n",
    "def term_frequency(document, word):\n",
    "    return document.count(word)\n",
    "\n",
    "tf = np.zeros((bag_of_words.shape[0], 10))\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(len(tf)):\n",
    "        tf[j, i] = term_frequency(corpus[i], bag_of_words[j])\n",
    "    #Normalizing the TF\n",
    "    tf[:, i] /= np.sum(tf[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the Inverse Document Frequency\n",
    "def document_frequency(document, word, count):\n",
    "    if word in document:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def inverse_document_frequency(df):\n",
    "    document_length = 10\n",
    "    return np.log(document_length/(df + 1))\n",
    "\n",
    "idf = np.zeros((tf.shape[0], 1))\n",
    "for i in range(len(bag_of_words)):\n",
    "    for document in corpus:\n",
    "        idf[i, 0] = document_frequency(document, bag_of_words[i], idf[i, 0])\n",
    "    idf[i, 0] = inverse_document_frequency(idf[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating tf * idf\n",
    "tf_idf = tf.copy()\n",
    "tf_idf = np.multiply(tf_idf, idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating Cosine Similarity\n",
    "def multiply_column_sum(doc1, doc2):\n",
    "    return np.sum(doc1 * doc2)\n",
    "\n",
    "def quadratic_sum(doc):\n",
    "    return math.sqrt(np.sum(np.square(doc)))\n",
    "\n",
    "def cosine_similarity(doc1, doc2):\n",
    "    return multiply_column_sum(doc1, doc2) / (quadratic_sum(doc1) * quadratic_sum(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Matrix yang Berisi Tingkat Kemiripan Antar Dokumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating matrix showing similarity of each document\n",
    "doc_similarity = np.empty((len(corpus), len(corpus)))\n",
    "for i in range(doc_similarity.shape[0]):\n",
    "    doc_similarity[i, i] = 1\n",
    "    for j in range(i+1, doc_similarity.shape[1]):\n",
    "        doc_similarity[i, j] = cosine_similarity(tf_idf[:, i], tf_idf[:, j])\n",
    "        doc_similarity[j, i] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merepresentasikan Tingkat Kemiripan Dalam Bentuk Tabel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "      <th>Doc3</th>\n",
       "      <th>Doc4</th>\n",
       "      <th>Doc5</th>\n",
       "      <th>Doc6</th>\n",
       "      <th>Doc7</th>\n",
       "      <th>Doc8</th>\n",
       "      <th>Doc9</th>\n",
       "      <th>Doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0227736</td>\n",
       "      <td>0.0196035</td>\n",
       "      <td>0.00435743</td>\n",
       "      <td>0.0253961</td>\n",
       "      <td>0.0494693</td>\n",
       "      <td>0.00833291</td>\n",
       "      <td>0.0810233</td>\n",
       "      <td>0.0690927</td>\n",
       "      <td>0.033174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0716329</td>\n",
       "      <td>0.0662852</td>\n",
       "      <td>0.0608412</td>\n",
       "      <td>0.0510323</td>\n",
       "      <td>0.138885</td>\n",
       "      <td>0.0483437</td>\n",
       "      <td>0.0595224</td>\n",
       "      <td>0.132859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0263141</td>\n",
       "      <td>0.00994799</td>\n",
       "      <td>0.0242179</td>\n",
       "      <td>0.00740318</td>\n",
       "      <td>0.0502603</td>\n",
       "      <td>0.00977117</td>\n",
       "      <td>0.049090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0524253</td>\n",
       "      <td>0.0667139</td>\n",
       "      <td>0.00214859</td>\n",
       "      <td>0.0242466</td>\n",
       "      <td>0.014976</td>\n",
       "      <td>0.011443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0464078</td>\n",
       "      <td>0.0243708</td>\n",
       "      <td>0.0159987</td>\n",
       "      <td>0.027802</td>\n",
       "      <td>0.036077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.104601</td>\n",
       "      <td>0.0747908</td>\n",
       "      <td>0.0372366</td>\n",
       "      <td>0.042170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0490705</td>\n",
       "      <td>0.0284846</td>\n",
       "      <td>0.067758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.081605</td>\n",
       "      <td>0.136908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.062150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Doc10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Doc1       Doc2       Doc3        Doc4        Doc5       Doc6  \\\n",
       "Doc1     1  0.0227736  0.0196035  0.00435743   0.0253961  0.0494693   \n",
       "Doc2                1  0.0716329   0.0662852   0.0608412  0.0510323   \n",
       "Doc3                           1   0.0263141  0.00994799  0.0242179   \n",
       "Doc4                                       1   0.0524253  0.0667139   \n",
       "Doc5                                                   1  0.0464078   \n",
       "Doc6                                                              1   \n",
       "Doc7                                                                  \n",
       "Doc8                                                                  \n",
       "Doc9                                                                  \n",
       "Doc10                                                                 \n",
       "\n",
       "             Doc7       Doc8        Doc9     Doc10  \n",
       "Doc1   0.00833291  0.0810233   0.0690927  0.033174  \n",
       "Doc2     0.138885  0.0483437   0.0595224  0.132859  \n",
       "Doc3   0.00740318  0.0502603  0.00977117  0.049090  \n",
       "Doc4   0.00214859  0.0242466    0.014976  0.011443  \n",
       "Doc5    0.0243708  0.0159987    0.027802  0.036077  \n",
       "Doc6     0.104601  0.0747908   0.0372366  0.042170  \n",
       "Doc7            1  0.0490705   0.0284846  0.067758  \n",
       "Doc8                       1    0.081605  0.136908  \n",
       "Doc9                                   1  0.062150  \n",
       "Doc10                                     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_labels = [\"Doc1\", \"Doc2\", \"Doc3\", \"Doc4\", \"Doc5\", \"Doc6\", \"Doc7\", \"Doc8\", \"Doc9\", \"Doc10\"]\n",
    "row_labels = [\"Doc1\", \"Doc2\", \"Doc3\", \"Doc4\", \"Doc5\", \"Doc6\", \"Doc7\", \"Doc8\", \"Doc9\", \"Doc10\"]\n",
    "a = pd.DataFrame(doc_similarity, columns=column_labels, index=row_labels)\n",
    "\n",
    "#Mengubah cell yang bernilai NaN menjadi empty string ('')\n",
    "a.replace(np.nan, '', inplace=True)\n",
    "\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
